{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a. Divide the dataset as train, development and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "                                                    text  label\n",
      "19524  [year, ago, watching, tv, news, story, broadca...      1\n",
      "19278  [movie, perfect, romantics, world, john, ritte...      1\n",
      "1240   [personally, think, show, looks, pretty, cheap...      0\n",
      "15820  [miss, company, vestron, sure, finger, pulse, ...      1\n",
      "19813  [pretty, memorable, movie, animalskillingpeopl...      1\n",
      "dev data:\n",
      "                                                    text  label\n",
      "19927  [know, thats, expect, film, sort, oflineage, d...      1\n",
      "20581  [first, dont, go, revolver, expecting, another...      1\n",
      "697    [really, wanted, like, movie, imposable, actin...      0\n",
      "9628   [seriously, american, frech, actors, pretendin...      0\n",
      "14311  [let, upfront, like, pulp, however, like, one,...      1\n",
      "\n",
      "\n",
      "test data:\n",
      "                                                text  label\n",
      "0  [alan, rickman, emma, thompson, give, good, pe...      0\n",
      "1  [seen, movie, care, movie, anyhow, would, thin...      0\n",
      "2  [los, angeles, alcoholic, lazy, hank, chinaski...      0\n",
      "3  [film, bundled, along, gli, fumavano, le, colt...      0\n",
      "4  [comment, really, good, films, utter, rubbish,...      0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_all_txt(direction):\n",
    "    allfiles = []\n",
    "    contents = os.listdir(direction)\n",
    "    for i in range(0,len(contents)):\n",
    "        path = os.path.join(direction,contents[i])\n",
    "        if os.path.isdir(path):\n",
    "            allfiles.extend(load_all_txt(path))\n",
    "        if os.path.isfile(path):\n",
    "            allfiles.append(path)\n",
    "    return allfiles\n",
    "\n",
    "train_list = load_all_txt('/Users/jizhimeicrc/Desktop/data/train')\n",
    "test_list = load_all_txt('/Users/jizhimeicrc/Desktop/data/test')\n",
    "\n",
    "def readfile(list):\n",
    "    new_sentences = []\n",
    "    for e in list:\n",
    "        f = open(e,'r')\n",
    "        line = f.readline()\n",
    "        new_sentences.append(line)\n",
    "    return new_sentences\n",
    "\n",
    "label = []\n",
    "for i in range(25000):\n",
    "    if i <= 12499:\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)\n",
    "\n",
    "sentences_train = readfile(train_list)\n",
    "sentences_test = readfile(test_list)\n",
    "train_dev = pd.DataFrame({'text':sentences_train,'label':label})\n",
    "train_dev = shuffle(train_dev)\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    # Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    # remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Applying the cleaning function to both test and training datasets\n",
    "train_dev['text'] = train_dev['text'].apply(lambda x: clean_text(x))\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "### divide the data as train and dev, train:dev = 4:1\n",
    "train = train_dev[:int(0.8*len(train_dev))]\n",
    "# train = train_dev[:2000]\n",
    "train = pd.DataFrame(train)\n",
    "dev = train_dev[int(0.8*len(train_dev)):]\n",
    "# dev = train_dev[2000:2400]\n",
    "dev = pd.DataFrame(dev)\n",
    "# tokenization\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "train['text'] = train['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "dev['text'] = dev['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "train['text'] = train['text'].apply(lambda x: remove_stopwords(x))\n",
    "dev['text'] = dev['text'].apply(lambda x: remove_stopwords(x))\n",
    "print(\"train data:\")\n",
    "print(train.head())\n",
    "print(\"dev data:\")\n",
    "print(dev.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "test = pd.DataFrame({'text':sentences_test,'label':label})\n",
    "test['text'] = test['text'].apply(lambda x: clean_text(x))\n",
    "test['text'] = test['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "test['text'] = test['text'].apply(lambda x: remove_stopwords(x))\n",
    "print(\"test data:\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b. Build a vocabulary as list. \n",
    "[‘the’ ‘I’ ‘happy’ … ] \n",
    "You may omit rare words for example if the occurrence is less than five times\n",
    "A reverse index as the key value might be handy\n",
    "{“the”: 0, “I”:1, “happy”:2 , … }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary list:\n",
      "[('year', 1413), ('ago', 794), ('watching', 3390), ('tv', 2024), ('news', 247), ('story', 9040), ('broadcast', 85), ('zombie', 567), ('movie', 31692), ('filmed', 568), ('area', 258), ('since', 2231), ('paid', 273), ('particular', 583), ('attention', 676), ('called', 1020), ('fido', 60), ('finished', 204), ('production', 1339), ('began', 244), ('playing', 1267), ('festivals', 42), ('two', 5217), ('weeks', 157), ('local', 689), ('theater', 604), ('yesterday', 73), ('read', 1416), ('newspaper', 93), ('article', 40), ('stated', 110), ('attracting', 9), ('audiences', 410), ('limited', 240), ('release', 578), ('exception', 280), ('fact', 2761), ('shows', 1913), ('paramount', 51), ('including', 814), ('course', 1951), ('makes', 3339), ('sense', 1797), ('many', 5155), ('locals', 52), ('want', 2909), ('see', 8791), ('city', 877), ('screen', 1686), ('spot', 269)]\n"
     ]
    }
   ],
   "source": [
    "def count_words(s):\n",
    "    s_list = s.lower().split(' ')\n",
    "    # calculate the occurrence of every word\n",
    "    top_n_dict = {}\n",
    "    for word in s_list:\n",
    "        if word in top_n_dict:\n",
    "            top_n_dict[word] += 1\n",
    "        else:\n",
    "            top_n_dict[word] = 1\n",
    "    return top_n_dict\n",
    "\n",
    "all_s = \"\"\n",
    "for index, row in train.iterrows():\n",
    "    s = \" \".join(row['text'])\n",
    "    all_s = all_s + s\n",
    "train_voc_list = count_words(all_s)\n",
    "\n",
    "for key, value in list(train_voc_list.items()):\n",
    "    if value==5 or value==4 or value==3 or value==2 or value==1:\n",
    "        del train_voc_list[key]\n",
    "# print(train_voc_list)\n",
    "print(\"vocabulary list:\")\n",
    "print(list(train_voc_list.items())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c. Calculate the following probability\n",
    "Probability of the occurrence\n",
    "P[“the”] = num of documents containing ‘the’ / num of all documents\n",
    "Conditional probability based on the sentiment\n",
    "P[“the” | Positive]  = # of positive documents containing “the” / num of all positive review documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior probability:\n",
      "[('year', 0.0621), ('ago', 0.038), ('watching', 0.14945), ('tv', 0.0793), ('news', 0.01105), ('story', 0.29605), ('broadcast', 0.00405), ('zombie', 0.0126), ('movie', 0.59835), ('filmed', 0.0267), ('area', 0.01115), ('since', 0.0979), ('paid', 0.01355), ('particular', 0.0277), ('attention', 0.03215), ('called', 0.04575), ('fido', 0.0011), ('finished', 0.0112), ('production', 0.05615), ('began', 0.01175)]\n",
      "\n",
      "conditional probability:\n",
      "positive:\n",
      " [('year', 0.07034675169390195), ('ago', 0.04453965723395775), ('watching', 0.12774013551215624), ('tv', 0.07811877241929055), ('news', 0.010661618174571542), ('story', 0.32781984854523716), ('broadcast', 0.0050817058589079315), ('zombie', 0.007174172977281785), ('movie', 0.5516141889198884), ('filmed', 0.027899561578318056), ('area', 0.011658031088082901), ('since', 0.10253088880031885), ('paid', 0.006974890394579514), ('particular', 0.033778397768035075), ('attention', 0.03626943005181347), ('called', 0.041550418493423676), ('fido', 0.0019928258270227183), ('finished', 0.009764846552411319), ('production', 0.0502192108409725), ('began', 0.01315265045834994)]\n",
      "\n",
      "\n",
      "negative:\n",
      " [('year', 0.05379365716579687), ('ago', 0.03141308711360899), ('watching', 0.17131674026495383), ('tv', 0.08048976314733039), ('news', 0.01144118827780008), ('story', 0.26405058209554394), ('broadcast', 0.003010839020473705), ('zombie', 0.018065034122842234), ('movie', 0.64542352468888), ('filmed', 0.02549177037334404), ('area', 0.010638297872340425), ('since', 0.09323564833400241), ('paid', 0.020172621437173827), ('particular', 0.021577679646728222), ('attention', 0.02800080289040546), ('called', 0.04997992773986351), ('fido', 0.0002007226013649137), ('finished', 0.012645523885989562), ('production', 0.062123645122440785), ('began', 0.010337213970293056)]\n"
     ]
    }
   ],
   "source": [
    "total_length = len(train)\n",
    "train_list = pd.DataFrame({'text':train['text'].apply(lambda x: count_words(\" \".join(x))), 'label':train['label']})\n",
    "\n",
    "def cal_total():\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for index, row in train.iterrows():\n",
    "        if row['label'] == 0:\n",
    "            neg = neg+1\n",
    "        if row['label'] == 1:\n",
    "            pos = pos+1\n",
    "    return pos, neg\n",
    "\n",
    "total_pos, total_neg = cal_total()\n",
    "\n",
    "def cal_prob():\n",
    "    prob = {}\n",
    "    con_p_pos = {}\n",
    "    con_p_neg = {}\n",
    "    for key in train_voc_list:\n",
    "        count = 0\n",
    "        count_pos = 0\n",
    "        count_neg = 0\n",
    "        for index, row in train_list.iterrows():\n",
    "            if key in row['text']:\n",
    "                count += 1\n",
    "                if row['label'] == 0:\n",
    "                    count_neg += 1\n",
    "                if row['label'] == 1:\n",
    "                    count_pos += 1\n",
    "        prob[key] = count/total_length;\n",
    "        con_p_pos[key] = count_pos/total_pos\n",
    "        con_p_neg[key] = count_neg/total_neg\n",
    "    return prob, con_p_pos, con_p_neg\n",
    "\n",
    "probability, conditional_p_pos, conditional_p_neg = cal_prob()\n",
    "\n",
    "print(\"prior probability:\")\n",
    "print(list(probability.items())[:20])\n",
    "\n",
    "print(\"\\nconditional probability:\")\n",
    "print(\"positive:\\n\", list(conditional_p_pos.items())[:20])\n",
    "print(\"\\n\")\n",
    "print(\"negative:\\n\", list(conditional_p_neg.items())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d. Calculate accuracy using dev dataset \n",
    "Conduct five fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.1 calculate accuracy using dev data before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "19927  [know, thats, expect, film, sort, oflineage, d...      1\n",
      "20581  [first, dont, go, revolver, expecting, another...      1\n",
      "697    [really, wanted, like, movie, imposable, actin...      0\n",
      "9628   [seriously, american, frech, actors, pretendin...      0\n",
      "14311  [let, upfront, like, pulp, however, like, one,...      1\n",
      "\n",
      "*********predict accuracy*********\n",
      "0.7982\n"
     ]
    }
   ],
   "source": [
    "print(dev.head())\n",
    "\n",
    "def classify(s):\n",
    "    pos_p = total_pos/len(train)\n",
    "    neg_p = total_neg/len(train)\n",
    "    for word in s:\n",
    "        if word in conditional_p_pos:\n",
    "            pos_p = pos_p*conditional_p_pos[word]\n",
    "        if word in conditional_p_neg:\n",
    "            neg_p = neg_p*conditional_p_neg[word]\n",
    "    if(pos_p>=neg_p):\n",
    "        return 1\n",
    "    if(pos_p<neg_p):\n",
    "        return 0\n",
    "\n",
    "right_num = 0\n",
    "for index, row in dev.iterrows():\n",
    "    if row['label']==classify(row['text']):\n",
    "        right_num += 1\n",
    "        \n",
    "accuracy = right_num/len(dev)\n",
    "print(\"\\n*********predict accuracy*********\")\n",
    "print(accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.2 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.95 \n",
      "\n",
      "accuracy:  0.93 \n",
      "\n",
      "accuracy:  0.93 \n",
      "\n",
      "accuracy:  0.955 \n",
      "\n",
      "accuracy:  0.925 \n",
      "\n",
      "\n",
      "*********predict accuracy*********\n",
      "0.9380000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(5, True, 10)\n",
    "train_dev_new = train_dev[:1000]\n",
    "train_dev_new = train_dev_new.values\n",
    "result = 0\n",
    "\n",
    "for train_idx, dev_idx in kf.split(train_dev_new):\n",
    "    train_new = train_dev_new[train_idx]\n",
    "    dev_new = train_dev_new[dev_idx]\n",
    "    train_new = pd.DataFrame(train_new)\n",
    "    dev_new = pd.DataFrame(dev_new)\n",
    "    train_new.rename(columns={0:'text'},inplace=True)\n",
    "    train_new.rename(columns={1:'label'},inplace=True)\n",
    "    dev_new.rename(columns={0:'text'},inplace=True)\n",
    "    dev_new.rename(columns={1:'label'},inplace=True)\n",
    "\n",
    "    for index, row in train_new.iterrows():\n",
    "        s1 = \" \".join(row['text'])\n",
    "        row['text'] = clean_text(s1)\n",
    "        row['text'] = tokenizer.tokenize(row['text'])\n",
    "        row['text'] = remove_stopwords(row['text'])\n",
    "        \n",
    "    for index, row in dev_new.iterrows():\n",
    "        s1 = \" \".join(row['text'])\n",
    "        row['text'] = clean_text(s1)\n",
    "        row['text'] = tokenizer.tokenize(row['text'])\n",
    "        row['text'] = remove_stopwords(row['text'])\n",
    "    \n",
    "    all_s = \"\"\n",
    "    for index, row in train_new.iterrows():\n",
    "        s = \" \".join(row['text'])\n",
    "        all_s = all_s + s\n",
    "    new_list = count_words(all_s)\n",
    "\n",
    "    for key, value in list(new_list.items()):\n",
    "        if value==5 or value==4 or value==3 or value==2 or value==1:\n",
    "            del new_list[key]\n",
    "            \n",
    "    total_length = len(train_new)\n",
    "    train_new_list = pd.DataFrame({'text':train_new['text'].apply(lambda x: count_words(\" \".join(x))), 'label':train_new['label']})\n",
    "    total_pos_new, total_neg_new = cal_total()\n",
    "    probability_new, conditional_p_pos_new, conditional_p_neg_new = cal_prob()\n",
    "    \n",
    "    right_num_new = 0\n",
    "    for index, row in dev_new.iterrows():\n",
    "        if row['label']==classify(row['text']):\n",
    "            right_num_new += 1\n",
    "        \n",
    "    accuracy_new = right_num_new/len(dev_new)\n",
    "    print(\"accuracy: \", accuracy_new, \"\\n\")\n",
    "    result += accuracy_new\n",
    "\n",
    "print(\"\\n*********predict accuracy*********\")\n",
    "print(result/5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e. Do following experiments\n",
    "Compare the effect of Smoothing\n",
    "Derive Top 10 words that predicts positive and negative class\n",
    "P[Positive| word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 of P[Positive| word]:\n",
      "one\n",
      "movie\n",
      "film\n",
      "like\n",
      "good\n",
      "great\n",
      "time\n",
      "story\n",
      "see\n",
      "well\n",
      "\n",
      "Top 10 of P[Negative| word]:\n",
      "movie\n",
      "one\n",
      "film\n",
      "like\n",
      "even\n",
      "good\n",
      "would\n",
      "bad\n",
      "time\n",
      "really\n"
     ]
    }
   ],
   "source": [
    "pos_word = {}\n",
    "neg_word = {}\n",
    "\n",
    "for key1 in conditional_p_pos:\n",
    "    if key1 in probability:\n",
    "        pos_word[key1] = (conditional_p_pos[key1]+1)/(probability[key1]+len(conditional_p_pos))\n",
    "a1 = sorted(pos_word.items(),key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "for key2 in conditional_p_neg:\n",
    "    if key2 in probability:\n",
    "        neg_word[key2] = (conditional_p_neg[key2]+1)/(probability[key2]+len(conditional_p_neg))\n",
    "a2 = sorted(neg_word.items(),key = lambda x:x[1], reverse = True)\n",
    "\n",
    "print(\"Top 10 of P[Positive| word]:\")\n",
    "for element in a1[:10]:\n",
    "    print(element[0])\n",
    "print(\"\\nTop 10 of P[Negative| word]:\")\n",
    "for element in a2[:10]:\n",
    "    print(element[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f. Using the test dataset\n",
    "Use the optimal hyperparameters you found in the step e, and use it to calculate the final accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********predict accuracy*********\n",
      "0.77736\n"
     ]
    }
   ],
   "source": [
    "pred_right = 0\n",
    "for index, row in test.iterrows():\n",
    "    if row['label']==classify(row['text']):\n",
    "        pred_right += 1\n",
    "accu = pred_right/len(test)\n",
    "print(\"*********predict accuracy*********\")\n",
    "print(accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
